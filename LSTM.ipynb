{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0zAGFCmeIDO0ZOf9KSiRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drashyabansel/GenerativeAI/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fGQ_qXDw2f3"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Virat Kohli (Hindi pronunciation is an Indian international cricketer who currently plays Test cricket\n",
        " and ODI cricket for India. Kohli is a former T20I player and a former\n",
        " and an occasional unorthodox right arm quick bowler. He currently\n",
        " represents Royal Challengers Bengaluru in the IPL and Delhi in\n",
        " domestic cricket. He holds the record as the highest run-scorer\n",
        " in IPL, ranks third in T20I, third in ODI, and stands as the\n",
        " fourth-highest in international cricket. [4] He also holds the record\n",
        " for scoring the most centuries in ODI cricket and stands\n",
        " second in the list of most international centuries scored. Hence,\n",
        " Kohli is widely regarded as one of the greatest batsmen of all time\n",
        " and the modern era. Kohli was a key member of the Indian team that\n",
        " won the 2011 Cricket World Cup, 2013 Champions Trophy and 2024 T20\n",
        " World Cup and captained India to win the ICC Test match three \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "GNDzQIN0yGMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWkPKGUTyJE4",
        "outputId": "487d93bc-cd02-43e0-9db4-ec824f7baf78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 18 08:09:15 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {word: i for i, word in enumerate(set(text.split()))}\n",
        "print(word2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyCBqEoXyLFE",
        "outputId": "341a7b24-dff5-456a-d089-124357e690c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'captained': 0, 'key': 1, 'ICC': 2, 'India': 3, 'World': 4, 'to': 5, 'also': 6, 'Cup': 7, 'widely': 8, '2024': 9, 'record': 10, 'holds': 11, 'pronunciation': 12, 'Challengers': 13, 'Hence,': 14, 'Trophy': 15, 'Royal': 16, 'ranks': 17, 'stands': 18, 'occasional': 19, 'regarded': 20, 'ODI': 21, 'modern': 22, 'second': 23, 'domestic': 24, '2013': 25, 'international': 26, 'era.': 27, 'cricket': 28, 'T20I,': 29, 'Delhi': 30, 'team': 31, 'all': 32, 'batsmen': 33, 'fourth-highest': 34, 'win': 35, 'in': 36, 'highest': 37, 'IPL,': 38, 'most': 39, '2011': 40, 'unorthodox': 41, 'player': 42, 'run-scorer': 43, '(Hindi': 44, 'cricket.': 45, 'third': 46, 'member': 47, 'Virat': 48, 'represents': 49, 'Kohli': 50, 'three': 51, 'He': 52, 'Cricket': 53, 'bowler.': 54, '[4]': 55, 'was': 56, 'T20': 57, 'IPL': 58, 'right': 59, 'greatest': 60, 'match': 61, 'of': 62, 'India.': 63, 'quick': 64, 'Champions': 65, 'cricketer': 66, 'a': 67, 'Test': 68, 'an': 69, 'T20I': 70, 'former': 71, 'Bengaluru': 72, 'scoring': 73, 'one': 74, 'as': 75, 'that': 76, 'for': 77, 'centuries': 78, 'Cup,': 79, 'scored.': 80, 'is': 81, 'plays': 82, 'the': 83, 'arm': 84, 'currently': 85, 'time': 86, 'Indian': 87, 'list': 88, 'who': 89, 'and': 90, 'ODI,': 91, 'won': 92}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "Kqfcw6DIyq0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In order to define any custom Dataset you need to define 3 class methods\n",
        "1. __init__\n",
        "2. __len__\n",
        "3. __getitem__"
      ],
      "metadata": {
        "id": "12dbChuMzRv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class customDataset(Dataset):\n",
        "  def __init__(self, text, word2idx, seq_length):\n",
        "    self.text = text\n",
        "    self.word2idx = word2idx\n",
        "    self.seq_length = seq_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text) - self.seq_length\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sequence = [self.word2idx[word] for word in self.text[index:index+self.seq_length]]\n",
        "    target = self.word2idx[self.text[index+self.seq_length]]\n",
        "    return torch.tensor(sequence), torch.tensor(target)\n",
        "\n",
        "dataset = customDataset(text.split(), word2idx, 5)"
      ],
      "metadata": {
        "id": "8czJO6IPzJ3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTO3ez8104Fj",
        "outputId": "cc45f0ca-d64a-4da1-9642-8444fd376908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([85, 82, 68, 28, 90]), tensor(21))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2word = {i:word for word,i in word2idx.items()}"
      ],
      "metadata": {
        "id": "kq7h_4i305YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "AQWOX1BY3U7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "7-rCygyQ3ZiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "pmy6YSAB3i84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_size, hidden_size) -> None:\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "    self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def forward(self, x, h0, c0):\n",
        "    embed = self.embed(x)\n",
        "    # out,h = self.lstm(embed, h0)\n",
        "    out,(h_n, c_n) = self.lstm(embed, (h0, c0))\n",
        "    output = self.fc(out[:,-1,:])\n",
        "    return output, (h_n, c_n)\n",
        "\n"
      ],
      "metadata": {
        "id": "nEcrMSi13maA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(vocab_size=len(word2idx), embed_size=100, hidden_size=256).to(\"cuda\")"
      ],
      "metadata": {
        "id": "rK-EfvfA4qz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "criteria = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "oRvyeU8v43Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train an LSTM Model"
      ],
      "metadata": {
        "id": "nxGl3pVL5MzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "  for input, label in dataloader:\n",
        "    input = input.to(\"cuda\")\n",
        "    label = label.to(\"cuda\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    h0 = torch.zeros(1, input.size(0), 256).to(\"cuda\")\n",
        "    c0 = torch.zeros(1, input.size(0), 256).to(\"cuda\")\n",
        "    outputs, _ = model(input, h0, c0)\n",
        "    loss = criteria(outputs, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"Epoch : {epoch} : Loss : {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_nG4h_45MZ0",
        "outputId": "89712641-5a48-44b2-b32a-41ea762ffd66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 : Loss : 4.521947383880615\n",
            "Epoch : 1 : Loss : 4.51588249206543\n",
            "Epoch : 2 : Loss : 4.459827899932861\n",
            "Epoch : 3 : Loss : 4.4485602378845215\n",
            "Epoch : 4 : Loss : 4.49717903137207\n",
            "Epoch : 5 : Loss : 4.433282375335693\n",
            "Epoch : 6 : Loss : 4.355049133300781\n",
            "Epoch : 7 : Loss : 4.374637126922607\n",
            "Epoch : 8 : Loss : 4.332235813140869\n",
            "Epoch : 9 : Loss : 4.428161144256592\n",
            "Epoch : 10 : Loss : 4.279419422149658\n",
            "Epoch : 11 : Loss : 4.438754558563232\n",
            "Epoch : 12 : Loss : 4.4265217781066895\n",
            "Epoch : 13 : Loss : 4.164323329925537\n",
            "Epoch : 14 : Loss : 4.2708001136779785\n",
            "Epoch : 15 : Loss : 4.311882495880127\n",
            "Epoch : 16 : Loss : 4.119652271270752\n",
            "Epoch : 17 : Loss : 4.242851734161377\n",
            "Epoch : 18 : Loss : 4.194119930267334\n",
            "Epoch : 19 : Loss : 4.279506683349609\n",
            "Epoch : 20 : Loss : 4.386092662811279\n",
            "Epoch : 21 : Loss : 4.265775680541992\n",
            "Epoch : 22 : Loss : 3.9238440990448\n",
            "Epoch : 23 : Loss : 3.8120718002319336\n",
            "Epoch : 24 : Loss : 4.0277485847473145\n",
            "Epoch : 25 : Loss : 3.3375377655029297\n",
            "Epoch : 26 : Loss : 4.110595226287842\n",
            "Epoch : 27 : Loss : 3.7418315410614014\n",
            "Epoch : 28 : Loss : 4.2845540046691895\n",
            "Epoch : 29 : Loss : 3.4091989994049072\n",
            "Epoch : 30 : Loss : 3.7367477416992188\n",
            "Epoch : 31 : Loss : 3.5110366344451904\n",
            "Epoch : 32 : Loss : 3.0789451599121094\n",
            "Epoch : 33 : Loss : 4.2226996421813965\n",
            "Epoch : 34 : Loss : 3.7822227478027344\n",
            "Epoch : 35 : Loss : 4.244115829467773\n",
            "Epoch : 36 : Loss : 3.2076635360717773\n",
            "Epoch : 37 : Loss : 4.075767517089844\n",
            "Epoch : 38 : Loss : 3.5226657390594482\n",
            "Epoch : 39 : Loss : 4.017021656036377\n",
            "Epoch : 40 : Loss : 3.5543620586395264\n",
            "Epoch : 41 : Loss : 3.2779810428619385\n",
            "Epoch : 42 : Loss : 3.7480478286743164\n",
            "Epoch : 43 : Loss : 3.675457715988159\n",
            "Epoch : 44 : Loss : 3.468963623046875\n",
            "Epoch : 45 : Loss : 3.7489144802093506\n",
            "Epoch : 46 : Loss : 4.119088649749756\n",
            "Epoch : 47 : Loss : 3.9336986541748047\n",
            "Epoch : 48 : Loss : 3.9751548767089844\n",
            "Epoch : 49 : Loss : 3.928673028945923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = torch.tensor([word2idx[word] for word in text.split()[-9:-4]]).unsqueeze(0).to(\"cuda\")\n",
        "h0 = torch.zeros(1, input_seq.size(0), 256).to(\"cuda\")\n",
        "c0 = torch.zeros(1, input_seq.size(0), 256).to(\"cuda\")"
      ],
      "metadata": {
        "id": "jl27_KLy5efK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out, _ = model(input_seq, h0, c0)"
      ],
      "metadata": {
        "id": "qD9Igmdr7Vvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.argmax().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2sKrp0M7Y16",
        "outputId": "71c4e7e2-1116-42a1-e1c9-20f9170adf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input Sequence : \", text.split()[-10:])\n",
        "print(\"Input Sequence : \", text.split()[-9:-4])\n",
        "\n",
        "print(\"The next word prediction : \", idx2word[out.argmax().item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OosXE8rD7rDR",
        "outputId": "84e0e4d1-9f7a-493c-a133-9811826cc675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence :  ['and', 'captained', 'India', 'to', 'win', 'the', 'ICC', 'Test', 'match', 'three']\n",
            "Input Sequence :  ['captained', 'India', 'to', 'win', 'the']\n",
            "The next word prediction :  record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_g_21RUd7s4D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}